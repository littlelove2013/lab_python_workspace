{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  \\\n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "8              9         1       3   \n",
      "9             10         1       2   \n",
      "10            11         1       3   \n",
      "11            12         1       1   \n",
      "15            16         1       2   \n",
      "21            22         1       2   \n",
      "22            23         1       3   \n",
      "23            24         1       1   \n",
      "25            26         1       3   \n",
      "39            40         1       3   \n",
      "43            44         1       2   \n",
      "44            45         1       3   \n",
      "52            53         1       1   \n",
      "53            54         1       2   \n",
      "56            57         1       2   \n",
      "58            59         1       2   \n",
      "61            62         1       1   \n",
      "66            67         1       2   \n",
      "68            69         1       3   \n",
      "74            75         1       3   \n",
      "78            79         1       2   \n",
      "79            80         1       3   \n",
      "81            82         1       3   \n",
      "84            85         1       2   \n",
      "85            86         1       3   \n",
      "88            89         1       1   \n",
      "97            98         1       1   \n",
      "..           ...       ...     ...   \n",
      "802          803         1       1   \n",
      "803          804         1       3   \n",
      "804          805         1       3   \n",
      "809          810         1       1   \n",
      "820          821         1       1   \n",
      "821          822         1       3   \n",
      "823          824         1       3   \n",
      "827          828         1       2   \n",
      "829          830         1       1   \n",
      "830          831         1       3   \n",
      "831          832         1       2   \n",
      "835          836         1       1   \n",
      "838          839         1       3   \n",
      "842          843         1       1   \n",
      "853          854         1       1   \n",
      "855          856         1       3   \n",
      "856          857         1       1   \n",
      "857          858         1       1   \n",
      "858          859         1       3   \n",
      "862          863         1       1   \n",
      "865          866         1       2   \n",
      "866          867         1       2   \n",
      "869          870         1       3   \n",
      "871          872         1       1   \n",
      "874          875         1       2   \n",
      "875          876         1       3   \n",
      "879          880         1       1   \n",
      "880          881         1       2   \n",
      "887          888         1       1   \n",
      "889          890         1       1   \n",
      "\n",
      "                                                  Name     Sex    Age  SibSp  \\\n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.00      1   \n",
      "2                               Heikkinen, Miss. Laina  female  26.00      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.00      1   \n",
      "8    Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.00      0   \n",
      "9                  Nasser, Mrs. Nicholas (Adele Achem)  female  14.00      1   \n",
      "10                     Sandstrom, Miss. Marguerite Rut  female   4.00      1   \n",
      "11                            Bonnell, Miss. Elizabeth  female  58.00      0   \n",
      "15                    Hewlett, Mrs. (Mary D Kingcome)   female  55.00      0   \n",
      "21                               Beesley, Mr. Lawrence    male  34.00      0   \n",
      "22                         McGowan, Miss. Anna \"Annie\"  female  15.00      0   \n",
      "23                        Sloper, Mr. William Thompson    male  28.00      0   \n",
      "25   Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...  female  38.00      1   \n",
      "39                         Nicola-Yarred, Miss. Jamila  female  14.00      1   \n",
      "43            Laroche, Miss. Simonne Marie Anne Andree  female   3.00      1   \n",
      "44                       Devaney, Miss. Margaret Delia  female  19.00      0   \n",
      "52            Harper, Mrs. Henry Sleeper (Myna Haxtun)  female  49.00      1   \n",
      "53   Faunthorpe, Mrs. Lizzie (Elizabeth Anne Wilkin...  female  29.00      1   \n",
      "56                                   Rugg, Miss. Emily  female  21.00      0   \n",
      "58                        West, Miss. Constance Mirium  female   5.00      1   \n",
      "61                                 Icard, Miss. Amelie  female  38.00      0   \n",
      "66                        Nye, Mrs. (Elizabeth Ramell)  female  29.00      0   \n",
      "68                     Andersson, Miss. Erna Alexandra  female  17.00      4   \n",
      "74                                       Bing, Mr. Lee    male  32.00      0   \n",
      "78                       Caldwell, Master. Alden Gates    male   0.83      0   \n",
      "79                            Dowdell, Miss. Elizabeth  female  30.00      0   \n",
      "81                         Sheerlinck, Mr. Jan Baptist    male  29.00      0   \n",
      "84                                 Ilett, Miss. Bertha  female  17.00      0   \n",
      "85   Backstrom, Mrs. Karl Alfred (Maria Mathilda Gu...  female  33.00      3   \n",
      "88                          Fortune, Miss. Mabel Helen  female  23.00      3   \n",
      "97                     Greenfield, Mr. William Bertram    male  23.00      0   \n",
      "..                                                 ...     ...    ...    ...   \n",
      "802                Carter, Master. William Thornton II    male  11.00      1   \n",
      "803                    Thomas, Master. Assad Alexander    male   0.42      0   \n",
      "804                            Hedman, Mr. Oskar Arvid    male  27.00      0   \n",
      "809     Chambers, Mrs. Norman Campbell (Bertha Griggs)  female  33.00      1   \n",
      "820  Hays, Mrs. Charles Melville (Clara Jennings Gr...  female  52.00      1   \n",
      "821                                  Lulic, Mr. Nikola    male  27.00      0   \n",
      "823                                 Moor, Mrs. (Beila)  female  27.00      0   \n",
      "827                              Mallet, Master. Andre    male   1.00      0   \n",
      "829          Stone, Mrs. George Nelson (Martha Evelyn)  female  62.00      0   \n",
      "830            Yasbeck, Mrs. Antoni (Selini Alexander)  female  15.00      1   \n",
      "831                    Richards, Master. George Sibley    male   0.83      1   \n",
      "835                        Compton, Miss. Sara Rebecca  female  39.00      1   \n",
      "838                                    Chip, Mr. Chang    male  32.00      0   \n",
      "842                            Serepeca, Miss. Augusta  female  30.00      0   \n",
      "853                          Lines, Miss. Mary Conover  female  16.00      0   \n",
      "855                         Aks, Mrs. Sam (Leah Rosen)  female  18.00      0   \n",
      "856         Wick, Mrs. George Dennick (Mary Hitchcock)  female  45.00      1   \n",
      "857                             Daly, Mr. Peter Denis     male  51.00      0   \n",
      "858              Baclini, Mrs. Solomon (Latifa Qurban)  female  24.00      0   \n",
      "862  Swift, Mrs. Frederick Joel (Margaret Welles Ba...  female  48.00      0   \n",
      "865                           Bystrom, Mrs. (Karolina)  female  42.00      0   \n",
      "866                       Duran y More, Miss. Asuncion  female  27.00      1   \n",
      "869                    Johnson, Master. Harold Theodor    male   4.00      1   \n",
      "871   Beckwith, Mrs. Richard Leonard (Sallie Monypeny)  female  47.00      1   \n",
      "874              Abelson, Mrs. Samuel (Hannah Wizosky)  female  28.00      1   \n",
      "875                   Najib, Miss. Adele Kiamie \"Jane\"  female  15.00      0   \n",
      "879      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)  female  56.00      0   \n",
      "880       Shelley, Mrs. William (Imanita Parrish Hall)  female  25.00      0   \n",
      "887                       Graham, Miss. Margaret Edith  female  19.00      0   \n",
      "889                              Behr, Mr. Karl Howell    male  26.00      0   \n",
      "\n",
      "     Parch            Ticket      Fare        Cabin Embarked  \n",
      "1        0          PC 17599   71.2833          C85        C  \n",
      "2        0  STON/O2. 3101282    7.9250          NaN        S  \n",
      "3        0            113803   53.1000         C123        S  \n",
      "8        2            347742   11.1333          NaN        S  \n",
      "9        0            237736   30.0708          NaN        C  \n",
      "10       1           PP 9549   16.7000           G6        S  \n",
      "11       0            113783   26.5500         C103        S  \n",
      "15       0            248706   16.0000          NaN        S  \n",
      "21       0            248698   13.0000          D56        S  \n",
      "22       0            330923    8.0292          NaN        Q  \n",
      "23       0            113788   35.5000           A6        S  \n",
      "25       5            347077   31.3875          NaN        S  \n",
      "39       0              2651   11.2417          NaN        C  \n",
      "43       2     SC/Paris 2123   41.5792          NaN        C  \n",
      "44       0            330958    7.8792          NaN        Q  \n",
      "52       0          PC 17572   76.7292          D33        C  \n",
      "53       0              2926   26.0000          NaN        S  \n",
      "56       0        C.A. 31026   10.5000          NaN        S  \n",
      "58       2        C.A. 34651   27.7500          NaN        S  \n",
      "61       0            113572   80.0000          B28      NaN  \n",
      "66       0        C.A. 29395   10.5000          F33        S  \n",
      "68       2           3101281    7.9250          NaN        S  \n",
      "74       0              1601   56.4958          NaN        S  \n",
      "78       2            248738   29.0000          NaN        S  \n",
      "79       0            364516   12.4750          NaN        S  \n",
      "81       0            345779    9.5000          NaN        S  \n",
      "84       0        SO/C 14885   10.5000          NaN        S  \n",
      "85       0           3101278   15.8500          NaN        S  \n",
      "88       2             19950  263.0000  C23 C25 C27        S  \n",
      "97       1          PC 17759   63.3583      D10 D12        C  \n",
      "..     ...               ...       ...          ...      ...  \n",
      "802      2            113760  120.0000      B96 B98        S  \n",
      "803      1              2625    8.5167          NaN        C  \n",
      "804      0            347089    6.9750          NaN        S  \n",
      "809      0            113806   53.1000           E8        S  \n",
      "820      1             12749   93.5000          B69        S  \n",
      "821      0            315098    8.6625          NaN        S  \n",
      "823      1            392096   12.4750         E121        S  \n",
      "827      2   S.C./PARIS 2079   37.0042          NaN        C  \n",
      "829      0            113572   80.0000          B28      NaN  \n",
      "830      0              2659   14.4542          NaN        C  \n",
      "831      1             29106   18.7500          NaN        S  \n",
      "835      1          PC 17756   83.1583          E49        C  \n",
      "838      0              1601   56.4958          NaN        S  \n",
      "842      0            113798   31.0000          NaN        C  \n",
      "853      1          PC 17592   39.4000          D28        S  \n",
      "855      1            392091    9.3500          NaN        S  \n",
      "856      1             36928  164.8667          NaN        S  \n",
      "857      0            113055   26.5500          E17        S  \n",
      "858      3              2666   19.2583          NaN        C  \n",
      "862      0             17466   25.9292          D17        S  \n",
      "865      0            236852   13.0000          NaN        S  \n",
      "866      0     SC/PARIS 2149   13.8583          NaN        C  \n",
      "869      1            347742   11.1333          NaN        S  \n",
      "871      1             11751   52.5542          D35        S  \n",
      "874      0         P/PP 3381   24.0000          NaN        C  \n",
      "875      0              2667    7.2250          NaN        C  \n",
      "879      1             11767   83.1583          C50        C  \n",
      "880      1            230433   26.0000          NaN        S  \n",
      "887      0            112053   30.0000          B42        S  \n",
      "889      0            111369   30.0000         C148        C  \n",
      "\n",
      "[290 rows x 12 columns]\n",
      "290\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-eeceba91b3c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_Survived\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;31m#分别获取Name对获救情况的影响\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m \u001b[0mdata_Survived\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'NameExtens'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msetName\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_Survived\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[0mdata_notSurvived\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'NameExtens'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msetName\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_notSurvived\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;31m#各登录港口乘客的获救情况\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-eeceba91b3c9>\u001b[0m in \u001b[0;36msetName\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mName_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Mr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Vision\\Anconda\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mH:\\Vision\\Anconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   2426\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2427\u001b[0m             return self._engine.get_value(s, k,\n\u001b[1;32m-> 2428\u001b[1;33m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[0;32m   2429\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2430\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'integer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'boolean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value (pandas\\_libs\\index.c:4363)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value (pandas\\_libs\\index.c:4046)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5085)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item (pandas\\_libs\\hashtable.c:13913)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item (pandas\\_libs\\hashtable.c:13857)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "import pandas as pd #数据分析\n",
    "import numpy as np #科学计算\n",
    "from pandas import Series,DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "#载入数据\n",
    "data_train = pd.read_csv(\"./train.csv\")\n",
    "#获取年龄不缺失的集合\n",
    "data_allage=data_train[data_train.Age.notnull()]\n",
    "#分别获取获救集合与未获救集合\n",
    "data_Survived=data_allage[data_allage.Survived == 1]\n",
    "data_notSurvived=data_allage[data_allage.Survived == 0]\n",
    "#对Name按 Mr,Miss,Mrs,Master,Norm分类\n",
    "def setName(data):\n",
    "#     print(data)\n",
    "    name=[]\n",
    "    Mr='^.* Mr\\. .*$'\n",
    "    Miss='^.* Miss\\. .*$'\n",
    "    Mrs='^.* Mrs\\. .*$'\n",
    "    Master='^.* Master\\. .*$'\n",
    "    lens = len(data)\n",
    "    print(lens)\n",
    "    Name_num=data.copy()\n",
    "    for i in range(lens):\n",
    "        print(i,data[i])\n",
    "        if re.match(Mr,data[i]):\n",
    "            name.append('Mr')\n",
    "            data.loc[i]='Mr'\n",
    "            Name_num.loc[i]=0\n",
    "        elif re.match(Miss,data[i]):\n",
    "            name.append('Miss')\n",
    "            data.loc[i]='Miss'\n",
    "            Name_num.loc[i]=1\n",
    "        elif re.match(Mrs,data[i]):\n",
    "            name.append('Mrs')\n",
    "            data.loc[i]='Mrs'\n",
    "            Name_num.loc[i]=2\n",
    "        elif re.match(Master,data[i]):\n",
    "            name.append('Master')\n",
    "            data.loc[i]='Master'\n",
    "            Name_num.loc[i]=3\n",
    "        else:\n",
    "            name.append('Norm')\n",
    "            data.loc[i]='Norm'\n",
    "            Name_num.loc[i]=4\n",
    "#     print(len(name),name)\n",
    "    #转换类型\n",
    "    Name_num=changeDtype(Name_num)\n",
    "#     print(data.values)\n",
    "    return data,Name_num\n",
    "#分别显示获救和未获救的曲线（数据为连续实数：dataflag=‘real’），或者直方图（数据为离散类别：dataflag='class'）\n",
    "def showDataFig(surviveddatalist,notsurviveddatalist,flag,title=None):\n",
    "    if(flag=='real'):#实数\n",
    "        surviveddatalist.plot(kind='kde')   \n",
    "        notsurviveddatalist.plot(kind='kde')\n",
    "        plt.legend((u'获救', u'未获救'),loc='best')\n",
    "    elif(flag=='class'):\n",
    "        #顺便统计有没有缺失值，给空出来\n",
    "        df=pd.DataFrame({ u'未获救':notsurviveddatalist.value_counts(),u'获救':surviveddatalist.value_counts()})\n",
    "        df.plot(kind='bar', stacked=True)\n",
    "    else:\n",
    "        return;\n",
    "    if title!=None:\n",
    "        plt.title(title)\n",
    "    plt.show()\n",
    "        \n",
    "#分析所有数值特征在获救和未获救数据集上的情况，主要看均值和方差\n",
    "#print(data_Survived.describe(),data_notSurvived.describe())\n",
    "sd=data_Survived.describe()\n",
    "snd=data_notSurvived.describe()\n",
    "sd.PassengerId.mean()\n",
    "print(data_Survived)\n",
    "#分别获取Name对获救情况的影响\n",
    "# data_Survived['NameExtens'],_=setName(data_Survived['Name'].copy())\n",
    "# data_notSurvived['NameExtens'],_=setName(data_notSurvived['Name'].copy())\n",
    "#各登录港口乘客的获救情况\n",
    "# showDataFig(data_Survived.NameExtens,data_notSurvived.NameExtens,'class','称呼的影响')\n",
    "#画出两类的年龄情况\n",
    "showDataFig(data_Survived.Age,data_notSurvived.Age,'real','两类的年龄情况')\n",
    "#Fare\t票价\n",
    "showDataFig(data_Survived.Fare,data_notSurvived.Fare,'real','Fare票价')\n",
    "\n",
    "#各登录港口乘客的获救情况\n",
    "showDataFig(data_Survived.Embarked,data_notSurvived.Embarked,'class','各登录港口乘客的获救情况')\n",
    "#乘客等级\n",
    "showDataFig(data_Survived.Pclass ,data_notSurvived.Pclass,'class','乘客等级')\n",
    "#乘客性别\n",
    "showDataFig(data_Survived.Sex ,data_notSurvived.Sex,'class','乘客性别')\n",
    "\n",
    "#考虑是独生子的人，可能会优先考虑（没有兄弟姐妹）\n",
    "#乘客堂兄弟/妹个数\n",
    "ds=data_Survived.copy()\n",
    "dns=data_notSurvived.copy()\n",
    "ds.loc[(data_Survived.SibSp != 0),'SibSp']=1\n",
    "dns.loc[(data_notSurvived.SibSp!=0),'SibSp']=1\n",
    "showDataFig(ds.SibSp ,dns.SibSp,'class','在船上的乘客堂兄弟/妹个数')\n",
    "#考虑乘客有父母或者子女的，可能要优先考虑\n",
    "#乘客父母与小孩个数\n",
    "ds.loc[(data_Survived.Parch != 0),'Parch']=1\n",
    "dns.loc[(data_notSurvived.Parch!=0),'Parch']=1\n",
    "showDataFig(ds.Parch  ,dns.Parch ,'class','船上乘客父母与小孩个数')\n",
    "#看Cabin有无对获救的影响\n",
    "ds.loc[(pd.notnull(data_train.Cabin)),'Cabin']=1\n",
    "dns.loc[(pd.notnull(data_train.Cabin)),'Cabin']=1\n",
    "ds.loc[(pd.isnull(data_train.Cabin)),'Cabin']=0\n",
    "dns.loc[(pd.isnull(data_train.Cabin)),'Cabin']=0\n",
    "showDataFig(ds.Cabin  ,dns.Cabin ,'class','Cabin特征有无的影响')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Pclass  Sex   Age  SibSp  Parch      Fare  Cabin  Embarked  \\\n",
      "0            892       3    0  34.5      0      0    7.8292      0         1   \n",
      "1            893       3    1  47.0      1      0    7.0000      0         2   \n",
      "2            894       2    0  62.0      0      0    9.6875      0         1   \n",
      "3            895       3    0  27.0      0      0    8.6625      0         2   \n",
      "4            896       3    1  22.0      1      1   12.2875      0         2   \n",
      "5            897       3    0  14.0      0      0    9.2250      0         2   \n",
      "6            898       3    1  30.0      0      0    7.6292      0         1   \n",
      "7            899       2    0  26.0      1      1   29.0000      0         2   \n",
      "8            900       3    1  18.0      0      0    7.2292      0         3   \n",
      "9            901       3    0  21.0      1      0   24.1500      0         2   \n",
      "10           902       3    0   NaN      0      0    7.8958      0         2   \n",
      "11           903       1    0  46.0      0      0   26.0000      0         2   \n",
      "12           904       1    1  23.0      1      0   82.2667      1         2   \n",
      "13           905       2    0  63.0      1      0   26.0000      0         2   \n",
      "14           906       1    1  47.0      1      0   61.1750      1         2   \n",
      "15           907       2    1  24.0      1      0   27.7208      0         3   \n",
      "16           908       2    0  35.0      0      0   12.3500      0         1   \n",
      "17           909       3    0  21.0      0      0    7.2250      0         3   \n",
      "18           910       3    1  27.0      1      0    7.9250      0         2   \n",
      "19           911       3    1  45.0      0      0    7.2250      0         3   \n",
      "20           912       1    0  55.0      1      0   59.4000      0         3   \n",
      "21           913       3    0   9.0      0      1    3.1708      0         2   \n",
      "22           914       1    1   NaN      0      0   31.6833      0         2   \n",
      "23           915       1    0  21.0      0      1   61.3792      0         3   \n",
      "24           916       1    1  48.0      1      1  262.3750      1         3   \n",
      "25           917       3    0  50.0      1      0   14.5000      0         2   \n",
      "26           918       1    1  22.0      0      1   61.9792      1         3   \n",
      "27           919       3    0  22.5      0      0    7.2250      0         3   \n",
      "28           920       1    0  41.0      0      0   30.5000      1         2   \n",
      "29           921       3    0   NaN      1      0   21.6792      0         3   \n",
      "..           ...     ...  ...   ...    ...    ...       ...    ...       ...   \n",
      "388         1280       3    0  21.0      0      0    7.7500      0         1   \n",
      "389         1281       3    0   6.0      1      1   21.0750      0         2   \n",
      "390         1282       1    0  23.0      0      0   93.5000      1         2   \n",
      "391         1283       1    1  51.0      0      1   39.4000      1         2   \n",
      "392         1284       3    0  13.0      0      1   20.2500      0         2   \n",
      "393         1285       2    0  47.0      0      0   10.5000      0         2   \n",
      "394         1286       3    0  29.0      1      1   22.0250      0         2   \n",
      "395         1287       1    1  18.0      1      0   60.0000      1         2   \n",
      "396         1288       3    0  24.0      0      0    7.2500      0         1   \n",
      "397         1289       1    1  48.0      1      1   79.2000      1         3   \n",
      "398         1290       3    0  22.0      0      0    7.7750      0         2   \n",
      "399         1291       3    0  31.0      0      0    7.7333      0         1   \n",
      "400         1292       1    1  30.0      0      0  164.8667      1         2   \n",
      "401         1293       2    0  38.0      1      0   21.0000      0         2   \n",
      "402         1294       1    1  22.0      0      1   59.4000      0         3   \n",
      "403         1295       1    0  17.0      0      0   47.1000      0         2   \n",
      "404         1296       1    0  43.0      1      0   27.7208      1         3   \n",
      "405         1297       2    0  20.0      0      0   13.8625      1         3   \n",
      "406         1298       2    0  23.0      1      0   10.5000      0         2   \n",
      "407         1299       1    0  50.0      1      1  211.5000      1         3   \n",
      "408         1300       3    1   NaN      0      0    7.7208      0         1   \n",
      "409         1301       3    1   3.0      1      1   13.7750      0         2   \n",
      "410         1302       3    1   NaN      0      0    7.7500      0         1   \n",
      "411         1303       1    1  37.0      1      0   90.0000      1         1   \n",
      "412         1304       3    1  28.0      0      0    7.7750      0         2   \n",
      "413         1305       3    0   NaN      0      0    8.0500      0         2   \n",
      "414         1306       1    1  39.0      0      0  108.9000      1         3   \n",
      "415         1307       3    0  38.5      0      0    7.2500      0         2   \n",
      "416         1308       3    0   NaN      0      0    8.0500      0         2   \n",
      "417         1309       3    0   NaN      1      1   22.3583      0         3   \n",
      "\n",
      "     Fare_scaled  \n",
      "0      -0.497311  \n",
      "1      -0.512175  \n",
      "2      -0.463999  \n",
      "3      -0.482373  \n",
      "4      -0.417392  \n",
      "5      -0.472290  \n",
      "6      -0.500896  \n",
      "7      -0.117805  \n",
      "8      -0.508066  \n",
      "9      -0.204746  \n",
      "10     -0.496117  \n",
      "11     -0.171583  \n",
      "12      0.837050  \n",
      "13     -0.171583  \n",
      "14      0.458962  \n",
      "15     -0.140736  \n",
      "16     -0.416271  \n",
      "17     -0.508142  \n",
      "18     -0.495594  \n",
      "19     -0.508142  \n",
      "20      0.427143  \n",
      "21     -0.580817  \n",
      "22     -0.069704  \n",
      "23      0.462622  \n",
      "24      4.065656  \n",
      "25     -0.377731  \n",
      "26      0.473378  \n",
      "27     -0.508142  \n",
      "28     -0.090916  \n",
      "29     -0.249037  \n",
      "..           ...  \n",
      "388    -0.498731  \n",
      "389    -0.259868  \n",
      "390     1.038417  \n",
      "391     0.068625  \n",
      "392    -0.274657  \n",
      "393    -0.449434  \n",
      "394    -0.242838  \n",
      "395     0.437899  \n",
      "396    -0.507694  \n",
      "397     0.782076  \n",
      "398    -0.498283  \n",
      "399    -0.499030  \n",
      "400     2.317730  \n",
      "401    -0.261212  \n",
      "402     0.427143  \n",
      "403     0.206654  \n",
      "404    -0.140736  \n",
      "405    -0.389158  \n",
      "406    -0.449434  \n",
      "407     3.153675  \n",
      "408    -0.499254  \n",
      "409    -0.390727  \n",
      "410    -0.498731  \n",
      "411     0.975676  \n",
      "412    -0.498283  \n",
      "413    -0.493353  \n",
      "414     1.314476  \n",
      "415    -0.507694  \n",
      "416    -0.493353  \n",
      "417    -0.236863  \n",
      "\n",
      "[418 rows x 10 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\Vision\\Anconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "H:\\Vision\\Anconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "H:\\Vision\\Anconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# data_pre=data_train.copy()\n",
    "data_pre=pd.read_csv(\"./test.csv\")\n",
    "#预处理数据，离散的映射到类别空间，连续的映射到[0,1]\n",
    "data_pre.drop(['Name', 'Ticket'], axis=1, inplace=True)\n",
    "def changeDtype(src,dstdtype='int64'):\n",
    "    a=src.values\n",
    "    a=np.array(a,dtype=dstdtype)\n",
    "    return a\n",
    "#离散值映射\n",
    "data_pre.loc[ (data_pre.Sex=='male'), 'Sex' ] = 0\n",
    "data_pre.loc[ (data_pre.Sex=='female'), 'Sex'] = 1\n",
    "data_pre.Sex=changeDtype(data_pre.Sex)\n",
    "\n",
    "data_pre.loc[ (data_pre.Cabin.notnull()), 'Cabin' ] = 1\n",
    "data_pre.loc[ (data_pre.Cabin.isnull()), 'Cabin' ] = 0\n",
    "data_pre.Cabin=changeDtype(data_pre.Cabin)\n",
    "\n",
    "data_pre.loc[ (data_pre.Embarked.isnull()), 'Embarked' ] = 0\n",
    "data_pre.loc[ (data_pre.Embarked=='Q'), 'Embarked' ] = 1\n",
    "data_pre.loc[ (data_pre.Embarked=='S'), 'Embarked' ] = 2\n",
    "data_pre.loc[ (data_pre.Embarked=='C'), 'Embarked' ] = 3\n",
    "data_pre.Embarked=changeDtype(data_pre.Embarked)\n",
    "\n",
    "data_pre.loc[(data_pre.Parch != 0),'Parch']=1\n",
    "\n",
    "data_pre.loc[(data_pre.SibSp != 0),'SibSp']=1\n",
    "#对实数变量，缩放到0-1\n",
    "import sklearn.preprocessing as preprocessing\n",
    "#对缺失的Fare，用Pclass对应的mean补上\n",
    "Fare_mean=[data_pre[data_pre.Pclass==1]['Fare'].mean(),data_pre[data_pre.Pclass==2]['Fare'].mean(),data_pre[data_pre.Pclass==3]['Fare'].mean()]\n",
    "Fare_mean=np.array(Fare_mean)\n",
    "data_pre.loc[pd.isnull(data_pre.Fare),'Fare']=Fare_mean[data_pre[pd.isnull(data_pre.Fare)]['Pclass'].as_matrix()-1]\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "fare_scale_param = scaler.fit(data_pre['Fare'])\n",
    "data_pre['Fare_scaled'] = scaler.fit_transform(data_pre['Fare'], fare_scale_param)\n",
    "\n",
    "print(data_pre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [PassengerId, Pclass, Sex, Age, SibSp, Parch, Fare, Cabin, Embarked]\n",
       "Index: []"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#随机森林\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "def getRFmodel(df,feature_list):\n",
    "    #取出特征\n",
    "    y=df[['Survived']].as_matrix()\n",
    "    #转换一下\n",
    "    y=y.ravel()\n",
    "    feature=df[feature_list].as_matrix()\n",
    "    #print(y)\n",
    "    rfr = RandomForestRegressor(random_state=0, n_estimators=2000, n_jobs=-1)\n",
    "    rfr.fit(feature, y)\n",
    "    return rfr,feature,y\n",
    "\n",
    "# feature_list=['Pclass','Sex','SibSp','Age_scaled','Parch','Fare_scaled','Cabin','Embarked']\n",
    "#feature_list=['Sex','Cabin','Embarked']\n",
    "# rfr,feature,y = getRFmodel(data_hasAge,feature_list)\n",
    "\n",
    "Fare_mean=[data_pre[data_pre.Pclass==1]['Fare'].mean(),data_pre[data_pre.Pclass==2]['Fare'].mean(),data_pre[data_pre.Pclass==3]['Fare'].mean()]\n",
    "Fare_mean=np.array(Fare_mean)\n",
    "data_pre.loc[pd.isnull(data_pre.Fare),'Fare']=Fare_mean[data_pre[pd.isnull(data_pre.Fare)]['Pclass'].as_matrix()-1]\n",
    "\n",
    "data_pre[pd.isnull(data_pre.Fare)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总样本集为891行，取测试集比例0.200000，取178个测试集，713个训练集\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\Vision\\Anconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "H:\\Vision\\Anconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "H:\\Vision\\Anconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "H:\\Vision\\Anconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "H:\\Vision\\Anconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "H:\\Vision\\Anconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def set_missing_ages(data,featurelist):\n",
    "    df=data.copy()\n",
    "    # 把已有的数值型特征取出来丢进Random Forest Regressor中\n",
    "    age_df = df[featurelist]\n",
    "    # 乘客分成已知年龄和未知年龄两部分\n",
    "    known_age = age_df[df.Age.notnull()].as_matrix()\n",
    "    unknown_age = age_df[df.Age.isnull()].as_matrix()\n",
    "\n",
    "    # y即目标年龄\n",
    "    y = df[df.Age.notnull()].Age.as_matrix()\n",
    "    # X即特征属性值\n",
    "    X = known_age\n",
    "\n",
    "    # fit到RandomForestRegressor之中\n",
    "    rfr = RandomForestRegressor(random_state=0, n_estimators=2000, n_jobs=-1)\n",
    "    rfr.fit(X, y)\n",
    "    # 用得到的模型进行未知年龄结果预测\n",
    "    predictedAges = rfr.predict(unknown_age)\n",
    "    # 用得到的预测结果填补原缺失数据\n",
    "    df.loc[ (df.Age.isnull()), 'Age' ] = predictedAges\n",
    "    return df\n",
    "#rate为取测试样本的比例\n",
    "def predata(file_path='./dataset/train.csv',ratio=0.2):\n",
    "    #读取\n",
    "    # 载入数据\n",
    "    data_train = pd.read_csv(file_path)\n",
    "    data_len=len(data_train)\n",
    "    test_number=int(ratio*(data_len))\n",
    "    train_number=data_len-test_number\n",
    "    print('总样本集为%d行，取测试集比例%f，取%d个测试集，%d个训练集'%(data_len,ratio,test_number,train_number))\n",
    "    data_pre = data_train.copy()\n",
    "    # 预处理数据，离散的映射到类别空间，连续的映射到[0,1]\n",
    "    data_pre.drop(['Name', 'Ticket'], axis=1, inplace=True)\n",
    "    # 离散值映射\n",
    "    data_pre.loc[(data_pre.Sex == 'male'), 'Sex'] = 0\n",
    "    data_pre.loc[(data_pre.Sex == 'female'), 'Sex'] = 1\n",
    "    data_pre.Sex = changeDtype(data_pre.Sex)\n",
    "\n",
    "    data_pre.loc[(data_pre.Cabin.notnull()), 'Cabin'] = 1\n",
    "    data_pre.loc[(data_pre.Cabin.isnull()), 'Cabin'] = 0\n",
    "    data_pre.Cabin = changeDtype(data_pre.Cabin)\n",
    "\n",
    "    data_pre.loc[(data_pre.Embarked.isnull()), 'Embarked'] = 0\n",
    "    data_pre.loc[(data_pre.Embarked == 'Q'), 'Embarked'] = 1\n",
    "    data_pre.loc[(data_pre.Embarked == 'S'), 'Embarked'] = 2\n",
    "    data_pre.loc[(data_pre.Embarked == 'C'), 'Embarked'] = 3\n",
    "    data_pre.Embarked = changeDtype(data_pre.Embarked)\n",
    "    data_pre.loc[(data_pre.Parch != 0), 'Parch'] = 1\n",
    "    data_pre.loc[(data_pre.SibSp != 0), 'SibSp'] = 1\n",
    "    # 对实数变量，缩放到0-1\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    fare_scale_param = scaler.fit(data_pre['Fare'])\n",
    "    data_pre['Fare_scaled'] = scaler.fit_transform(data_pre['Fare'], fare_scale_param)\n",
    "    #预测缺失的age值\n",
    "    featurelist=['Pclass','Sex','SibSp','Fare_scaled','Parch','Cabin','Embarked']\n",
    "    data_pre=set_missing_ages(data_pre,featurelist)\n",
    "    #并归一化\n",
    "    fare_scale_param = scaler.fit(data_pre['Age'])\n",
    "    data_pre['Age_scaled'] = scaler.fit_transform(data_pre['Age'], fare_scale_param)\n",
    "    #分别获取其特征和标签矩阵\n",
    "    featurelist2 = ['Survived','Pclass', 'Sex', 'SibSp', 'Fare_scaled','Age_scaled', 'Parch', 'Cabin', 'Embarked']\n",
    "    data=data_pre[featurelist2].as_matrix()\n",
    "    # 分出测试集和训练集\n",
    "    data_test = data[:test_number,1:]\n",
    "    label_test=data[:test_number,0]\n",
    "    data_train = data[test_number:,1:]\n",
    "    label_train = data[test_number:, 0]\n",
    "    #\n",
    "    return data_test,label_test,data_train,label_train\n",
    "te,te_l,tr,tr_l=predata('./train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  0.,  0., ...,  0.,  0.,  2.],\n",
       "       [ 3.,  0.,  0., ...,  0.,  0.,  2.],\n",
       "       [ 3.,  1.,  1., ...,  1.,  0.,  2.],\n",
       "       ..., \n",
       "       [ 3.,  1.,  1., ...,  1.,  0.,  2.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  1.,  3.],\n",
       "       [ 3.,  0.,  0., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1238facb30ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdummies_Cabin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_pre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Cabin'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'Cabin'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdummies_Embarked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_pre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Embarked'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'Embarked'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdummies_Parch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_pre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Parch'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'Parch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdummies_SibSp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_pre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SibSp'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'SibSp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdummies_Pclass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_pre\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Pclass'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'Pclass'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "dummies_Cabin = pd.get_dummies(data_pre['Cabin'], prefix= 'Cabin')\n",
    "dummies_Embarked = pd.get_dummies(data_pre['Embarked'], prefix= 'Embarked')\n",
    "dummies_Parch = pd.get_dummies(data_pre['Parch'], prefix= 'Parch')\n",
    "dummies_SibSp = pd.get_dummies(data_pre['SibSp'], prefix= 'SibSp')\n",
    "dummies_Pclass = pd.get_dummies(data_pre['Pclass'], prefix= 'Pclass')\n",
    "dummies_Sex = pd.get_dummies(data_pre['Sex'], prefix= 'Sex')\n",
    "df = pd.concat([data_pre, dummies_Cabin, dummies_Embarked,dummies_Parch,dummies_SibSp, dummies_Sex, dummies_Pclass], axis=1)\n",
    "#去除源类\n",
    "df.drop(['Pclass','Sex','SibSp','Parch', 'Cabin', 'Embarked'], axis=1, inplace=True)\n",
    "#featurelist2 = ['Survived', 'Pclass', 'Sex', 'SibSp', 'Fare_scaled', 'Age_scaled', 'Parch', 'Cabin', 'Embarked']\n",
    "        #获取需要的类别\n",
    "data = df.filter(regex='Survived|Age_.*|SibSp|Parch_.*|Fare_.*|Cabin_.*|Embarked_.*|Sex_.*|Pclass_.*').as_matrix()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
